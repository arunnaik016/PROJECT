{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMyiqKH3JFqv7r9ueP3kcP0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EO-q1S9EiVLR","executionInfo":{"status":"ok","timestamp":1712040378505,"user_tz":-330,"elapsed":28720,"user":{"displayName":"Arun Kumar","userId":"06687701211405974628"}},"outputId":"64ecddca-0373-42d4-c4f4-fc9e1251774b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["#Mounting the Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","data_root='/content/drive/My Drive/projects/chat-bot'\n","#Please upload the files in your drive and change the path to it accordingly."]},{"cell_type":"code","source":["#2 Importing Relevant Libraries\n","import json\n","import string\n","import random\n","\n","import nltk\n","import numpy as np\n","from nltk.stem import WordNetLemmatizer\n","import tensorflow as tf\n","from tensorflow.keras import Sequential\n","from tensorflow.keras.layers import Dense, Dropout\n","nltk.download(\"punkt\")\n","nltk.download(\"wordnet\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t22sdEBKkYHK","executionInfo":{"status":"ok","timestamp":1712040602435,"user_tz":-330,"elapsed":8206,"user":{"displayName":"Arun Kumar","userId":"06687701211405974628"}},"outputId":"aade1168-0e08-43ab-b021-6a14d139d5dc"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["#Loading the Dataset: intents.json\n","data_file = open(data_root + '/intents.json').read()\n","data = json.loads(data_file)"],"metadata":{"id":"GOzjZgkLkq2H","executionInfo":{"status":"ok","timestamp":1712040804194,"user_tz":-330,"elapsed":728,"user":{"displayName":"Arun Kumar","userId":"06687701211405974628"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["data"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nB59USdFlZwW","executionInfo":{"status":"ok","timestamp":1712040833925,"user_tz":-330,"elapsed":18,"user":{"displayName":"Arun Kumar","userId":"06687701211405974628"}},"outputId":"a43d0ca4-1c8f-4867-a740-4cb076f0bfa6"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'intents': [{'tag': 'greeting',\n","   'patterns': ['Hi', 'How are you', 'Is anyone there?', 'Hello', 'Good day'],\n","   'responses': ['Hello, thanks for visiting',\n","    'Good to see you again',\n","    'Hi there, how can I help?'],\n","   'context_set': ''},\n","  {'tag': 'goodbye',\n","   'patterns': ['Bye', 'See you later', 'Goodbye'],\n","   'responses': ['See you later, thanks for visiting',\n","    'Have a nice day',\n","    'Bye! Come back again soon.']},\n","  {'tag': 'thanks',\n","   'patterns': ['Thanks', 'Thank you', \"That's helpful\"],\n","   'responses': ['Happy to help!', 'Any time!', 'My pleasure']},\n","  {'tag': 'hours',\n","   'patterns': ['What hours are you open?',\n","    'What are your hours?',\n","    'When are you open?'],\n","   'responses': [\"We're open every day 9am-9pm\",\n","    'Our hours are 9am-9pm every day']},\n","  {'tag': 'payments',\n","   'patterns': ['Do you take credit cards?',\n","    'Do you accept Mastercard?',\n","    'Are you cash only?'],\n","   'responses': ['We accept VISA, Mastercard and AMEX',\n","    'We accept most major credit cards']},\n","  {'tag': 'opentoday',\n","   'patterns': ['Are you open today?',\n","    'When do you open today?',\n","    'What are your hours today?'],\n","   'responses': [\"We're open every day from 9am-9pm\",\n","    'Our hours are 9am-9pm every day']},\n","  {'tag': 'weathertoday',\n","   'patterns': ['What is weather today?', \"What is today's temprature?\"],\n","   'responses': ['weather today : 30']},\n","  {'tag': 'weathertomorrow',\n","   'patterns': ['What will be weather tomorrow?',\n","    \"What will be tomorrow's temprature?\"],\n","   'responses': ['weather tomorrow : 40']}]}"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["#Creating data X and data_Y\n","\n","words = [] #For Bow nodel/ vocabulary for patterns\n","classes = [] #For Bow model/ vocabulary for tags\n","data_X = [] #For storing each pattern\n","data_y = [] #For storing tag corresponding to each pattern in data X\n","\n","# Iterating over all the intents\n","\n","for intent in data[\"intents\"]:\n","  for pattern in intent[\"patterns\"]:\n","    tokens = nltk.word_tokenize(pattern) # tokenize each pattern.\n","    words.extend(tokens) #and append tokens to words\n","    data_X.append(pattern) #appending pattern to data X\n","    data_y.append(intent[\"tag\"]), #appending the associated tag to each pattern\n","\n","  # adding the tag to the classes if it's not there already\n","  if intent[\"tag\"] not in classes:\n","    classes.append(intent[\"tag\"])\n","\n","# initializing lemmatizer to get stem of words\n","lemmatizer = WordNetLemmatizer()\n","\n","\n","#lemmatize all the words in the vocab and convert them lowercase\n","#if the words dont apeear in punctuation\n","words = [lemmatizer.lemmatize(word.lower()) for word in words if word not in string.punctuation]\n","#sorting the vocab and classes in alphabetical order and taking the # set to ensure no duplicates occur\n","words = sorted(set(words))\n","classes = sorted(set(classes))"],"metadata":{"id":"ZKJC8Jq5leiG","executionInfo":{"status":"ok","timestamp":1712041450746,"user_tz":-330,"elapsed":2123,"user":{"displayName":"Arun Kumar","userId":"06687701211405974628"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["#5 Text to Numbers\n","training = []\n","out_empty = [0]*len(classes)\n","# creating the bag of words model\n","\n","for idx, doc in enumerate(data_X):\n","  bow  =[]\n","  text = lemmatizer.lemmatize(doc.lower())\n","  for word in words:\n","    bow.append(1) if word in text else bow.append(0)\n","  # mark the index of class that the current pattern is associated\n","  #to\n","  output_row = list(out_empty)\n","  output_row[classes.index(data_y[idx])] = 1\n","  #add the one hot encoded Boll and associated classes to training\n","  training.append([bow, output_row])\n","#shuffle the data and convert it to an array\n","random.shuffle(training)\n","training = np.array(training, dtype=object)\n","#split the features and target labels\n","train_X= np.array(list(training[:, 0]))\n","train_Y= np.array(list(training[:, 1]))"],"metadata":{"id":"EObvfG2Xrfrh","executionInfo":{"status":"ok","timestamp":1712042543939,"user_tz":-330,"elapsed":670,"user":{"displayName":"Arun Kumar","userId":"06687701211405974628"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["#6 The Neural Network Model\n","model = Sequential()\n","model.add(Dense(128, input_shape=(len(train_X[0]),), activation=\"relu\"))\n","model.add(Dropout(0.5))\n","model.add(Dense (64, activation=\"relu\"))\n","model.add(Dropout(0.5))\n","model.add(Dense(len(train_Y[0]), activation = \"softmax\"))\n","adam = tf.keras.optimizers.legacy.Adam(learning_rate=0.01, decay=1e-6)\n","model.compile(loss='categorical_crossentropy',\n","              optimizer=adam,\n","              metrics=[\"accuracy\"])\n","print(model.summary())\n","model.fit(x=train_X, y=train_Y, epochs=150, verbose=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"miwu4JK7rfzA","executionInfo":{"status":"ok","timestamp":1712042845028,"user_tz":-330,"elapsed":6699,"user":{"displayName":"Arun Kumar","userId":"06687701211405974628"}},"outputId":"f8754e7a-9732-40e5-8aa0-9d1d6c2556d8"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_3\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_9 (Dense)             (None, 128)               4992      \n","                                                                 \n"," dropout_6 (Dropout)         (None, 128)               0         \n","                                                                 \n"," dense_10 (Dense)            (None, 64)                8256      \n","                                                                 \n"," dropout_7 (Dropout)         (None, 64)                0         \n","                                                                 \n"," dense_11 (Dense)            (None, 8)                 520       \n","                                                                 \n","=================================================================\n","Total params: 13768 (53.78 KB)\n","Trainable params: 13768 (53.78 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n","Epoch 1/150\n","1/1 [==============================] - 1s 924ms/step - loss: 2.0055 - accuracy: 0.2083\n","Epoch 2/150\n","1/1 [==============================] - 0s 28ms/step - loss: 1.9905 - accuracy: 0.2083\n","Epoch 3/150\n","1/1 [==============================] - 0s 22ms/step - loss: 2.0063 - accuracy: 0.2083\n","Epoch 4/150\n","1/1 [==============================] - 0s 20ms/step - loss: 1.6642 - accuracy: 0.6250\n","Epoch 5/150\n","1/1 [==============================] - 0s 26ms/step - loss: 1.6709 - accuracy: 0.4167\n","Epoch 6/150\n","1/1 [==============================] - 0s 22ms/step - loss: 1.4780 - accuracy: 0.5833\n","Epoch 7/150\n","1/1 [==============================] - 0s 38ms/step - loss: 1.2051 - accuracy: 0.6667\n","Epoch 8/150\n","1/1 [==============================] - 0s 23ms/step - loss: 1.2829 - accuracy: 0.7083\n","Epoch 9/150\n","1/1 [==============================] - 0s 25ms/step - loss: 1.1392 - accuracy: 0.6667\n","Epoch 10/150\n","1/1 [==============================] - 0s 24ms/step - loss: 1.0293 - accuracy: 0.8750\n","Epoch 11/150\n","1/1 [==============================] - 0s 34ms/step - loss: 0.7411 - accuracy: 0.8750\n","Epoch 12/150\n","1/1 [==============================] - 0s 29ms/step - loss: 0.8487 - accuracy: 0.7917\n","Epoch 13/150\n","1/1 [==============================] - 0s 28ms/step - loss: 0.5082 - accuracy: 0.9167\n","Epoch 14/150\n","1/1 [==============================] - 0s 28ms/step - loss: 0.5723 - accuracy: 0.8333\n","Epoch 15/150\n","1/1 [==============================] - 0s 28ms/step - loss: 0.5198 - accuracy: 0.9583\n","Epoch 16/150\n","1/1 [==============================] - 0s 20ms/step - loss: 0.2494 - accuracy: 0.9583\n","Epoch 17/150\n","1/1 [==============================] - 0s 35ms/step - loss: 0.4200 - accuracy: 0.9167\n","Epoch 18/150\n","1/1 [==============================] - 0s 34ms/step - loss: 0.3602 - accuracy: 0.9583\n","Epoch 19/150\n","1/1 [==============================] - 0s 24ms/step - loss: 0.2202 - accuracy: 0.9583\n","Epoch 20/150\n","1/1 [==============================] - 0s 19ms/step - loss: 0.2332 - accuracy: 0.9167\n","Epoch 21/150\n","1/1 [==============================] - 0s 22ms/step - loss: 0.3464 - accuracy: 0.8333\n","Epoch 22/150\n","1/1 [==============================] - 0s 36ms/step - loss: 0.3800 - accuracy: 0.9167\n","Epoch 23/150\n","1/1 [==============================] - 0s 24ms/step - loss: 0.2693 - accuracy: 0.8750\n","Epoch 24/150\n","1/1 [==============================] - 0s 21ms/step - loss: 0.1422 - accuracy: 0.9583\n","Epoch 25/150\n","1/1 [==============================] - 0s 27ms/step - loss: 0.0709 - accuracy: 1.0000\n","Epoch 26/150\n","1/1 [==============================] - 0s 22ms/step - loss: 0.0596 - accuracy: 1.0000\n","Epoch 27/150\n","1/1 [==============================] - 0s 20ms/step - loss: 0.0636 - accuracy: 1.0000\n","Epoch 28/150\n","1/1 [==============================] - 0s 30ms/step - loss: 0.0991 - accuracy: 1.0000\n","Epoch 29/150\n","1/1 [==============================] - 0s 22ms/step - loss: 0.2655 - accuracy: 0.8750\n","Epoch 30/150\n","1/1 [==============================] - 0s 29ms/step - loss: 0.0696 - accuracy: 1.0000\n","Epoch 31/150\n","1/1 [==============================] - 0s 13ms/step - loss: 0.1394 - accuracy: 1.0000\n","Epoch 32/150\n","1/1 [==============================] - 0s 14ms/step - loss: 0.1520 - accuracy: 0.9583\n","Epoch 33/150\n","1/1 [==============================] - 0s 15ms/step - loss: 0.0664 - accuracy: 1.0000\n","Epoch 34/150\n","1/1 [==============================] - 0s 15ms/step - loss: 0.1343 - accuracy: 0.9583\n","Epoch 35/150\n","1/1 [==============================] - 0s 15ms/step - loss: 0.0921 - accuracy: 0.9583\n","Epoch 36/150\n","1/1 [==============================] - 0s 16ms/step - loss: 0.1098 - accuracy: 1.0000\n","Epoch 37/150\n","1/1 [==============================] - 0s 17ms/step - loss: 0.0268 - accuracy: 1.0000\n","Epoch 38/150\n","1/1 [==============================] - 0s 15ms/step - loss: 0.0325 - accuracy: 1.0000\n","Epoch 39/150\n","1/1 [==============================] - 0s 15ms/step - loss: 0.0211 - accuracy: 1.0000\n","Epoch 40/150\n","1/1 [==============================] - 0s 14ms/step - loss: 0.1450 - accuracy: 0.9583\n","Epoch 41/150\n","1/1 [==============================] - 0s 14ms/step - loss: 0.0493 - accuracy: 0.9583\n","Epoch 42/150\n","1/1 [==============================] - 0s 14ms/step - loss: 0.0734 - accuracy: 0.9583\n","Epoch 43/150\n","1/1 [==============================] - 0s 14ms/step - loss: 0.0805 - accuracy: 0.9583\n","Epoch 44/150\n","1/1 [==============================] - 0s 15ms/step - loss: 0.0494 - accuracy: 1.0000\n","Epoch 45/150\n","1/1 [==============================] - 0s 15ms/step - loss: 0.0888 - accuracy: 0.9167\n","Epoch 46/150\n","1/1 [==============================] - 0s 14ms/step - loss: 0.1174 - accuracy: 0.9167\n","Epoch 47/150\n","1/1 [==============================] - 0s 14ms/step - loss: 0.1251 - accuracy: 0.9583\n","Epoch 48/150\n","1/1 [==============================] - 0s 15ms/step - loss: 0.1034 - accuracy: 0.9167\n","Epoch 49/150\n","1/1 [==============================] - 0s 19ms/step - loss: 0.0704 - accuracy: 0.9583\n","Epoch 50/150\n","1/1 [==============================] - 0s 22ms/step - loss: 0.0092 - accuracy: 1.0000\n","Epoch 51/150\n","1/1 [==============================] - 0s 22ms/step - loss: 0.0098 - accuracy: 1.0000\n","Epoch 52/150\n","1/1 [==============================] - 0s 20ms/step - loss: 0.0229 - accuracy: 1.0000\n","Epoch 53/150\n","1/1 [==============================] - 0s 15ms/step - loss: 0.0306 - accuracy: 1.0000\n","Epoch 54/150\n","1/1 [==============================] - 0s 14ms/step - loss: 0.0665 - accuracy: 0.9583\n","Epoch 55/150\n","1/1 [==============================] - 0s 18ms/step - loss: 0.0536 - accuracy: 0.9583\n","Epoch 56/150\n","1/1 [==============================] - 0s 17ms/step - loss: 0.1078 - accuracy: 0.9167\n","Epoch 57/150\n","1/1 [==============================] - 0s 17ms/step - loss: 0.0246 - accuracy: 1.0000\n","Epoch 58/150\n","1/1 [==============================] - 0s 18ms/step - loss: 0.1364 - accuracy: 0.9167\n","Epoch 59/150\n","1/1 [==============================] - 0s 16ms/step - loss: 0.1477 - accuracy: 0.9583\n","Epoch 60/150\n","1/1 [==============================] - 0s 15ms/step - loss: 0.0828 - accuracy: 0.9583\n","Epoch 61/150\n","1/1 [==============================] - 0s 15ms/step - loss: 0.0299 - accuracy: 1.0000\n","Epoch 62/150\n","1/1 [==============================] - 0s 17ms/step - loss: 0.0236 - accuracy: 1.0000\n","Epoch 63/150\n","1/1 [==============================] - 0s 14ms/step - loss: 0.1172 - accuracy: 0.9583\n","Epoch 64/150\n","1/1 [==============================] - 0s 13ms/step - loss: 0.0094 - accuracy: 1.0000\n","Epoch 65/150\n","1/1 [==============================] - 0s 14ms/step - loss: 0.0134 - accuracy: 1.0000\n","Epoch 66/150\n","1/1 [==============================] - 0s 13ms/step - loss: 0.0372 - accuracy: 1.0000\n","Epoch 67/150\n","1/1 [==============================] - 0s 16ms/step - loss: 0.0064 - accuracy: 1.0000\n","Epoch 68/150\n","1/1 [==============================] - 0s 15ms/step - loss: 0.0077 - accuracy: 1.0000\n","Epoch 69/150\n","1/1 [==============================] - 0s 16ms/step - loss: 0.0170 - accuracy: 1.0000\n","Epoch 70/150\n","1/1 [==============================] - 0s 14ms/step - loss: 0.1089 - accuracy: 0.9583\n","Epoch 71/150\n","1/1 [==============================] - 0s 17ms/step - loss: 0.0165 - accuracy: 1.0000\n","Epoch 72/150\n","1/1 [==============================] - 0s 18ms/step - loss: 0.0054 - accuracy: 1.0000\n","Epoch 73/150\n","1/1 [==============================] - 0s 13ms/step - loss: 0.0643 - accuracy: 0.9583\n","Epoch 74/150\n","1/1 [==============================] - 0s 13ms/step - loss: 0.0221 - accuracy: 1.0000\n","Epoch 75/150\n","1/1 [==============================] - 0s 12ms/step - loss: 0.0172 - accuracy: 1.0000\n","Epoch 76/150\n","1/1 [==============================] - 0s 12ms/step - loss: 0.0128 - accuracy: 1.0000\n","Epoch 77/150\n","1/1 [==============================] - 0s 13ms/step - loss: 0.0048 - accuracy: 1.0000\n","Epoch 78/150\n","1/1 [==============================] - 0s 13ms/step - loss: 0.0137 - accuracy: 1.0000\n","Epoch 79/150\n","1/1 [==============================] - 0s 13ms/step - loss: 0.0332 - accuracy: 1.0000\n","Epoch 80/150\n","1/1 [==============================] - 0s 14ms/step - loss: 0.0129 - accuracy: 1.0000\n","Epoch 81/150\n","1/1 [==============================] - 0s 13ms/step - loss: 0.0112 - accuracy: 1.0000\n","Epoch 82/150\n","1/1 [==============================] - 0s 19ms/step - loss: 0.0282 - accuracy: 1.0000\n","Epoch 83/150\n","1/1 [==============================] - 0s 12ms/step - loss: 0.0324 - accuracy: 1.0000\n","Epoch 84/150\n","1/1 [==============================] - 0s 13ms/step - loss: 0.0202 - accuracy: 1.0000\n","Epoch 85/150\n","1/1 [==============================] - 0s 19ms/step - loss: 0.0447 - accuracy: 1.0000\n","Epoch 86/150\n","1/1 [==============================] - 0s 15ms/step - loss: 0.0051 - accuracy: 1.0000\n","Epoch 87/150\n","1/1 [==============================] - 0s 13ms/step - loss: 0.0068 - accuracy: 1.0000\n","Epoch 88/150\n","1/1 [==============================] - 0s 13ms/step - loss: 0.0542 - accuracy: 0.9583\n","Epoch 89/150\n","1/1 [==============================] - 0s 13ms/step - loss: 0.0467 - accuracy: 0.9583\n","Epoch 90/150\n","1/1 [==============================] - 0s 13ms/step - loss: 0.0160 - accuracy: 1.0000\n","Epoch 91/150\n","1/1 [==============================] - 0s 14ms/step - loss: 0.0039 - accuracy: 1.0000\n","Epoch 92/150\n","1/1 [==============================] - 0s 13ms/step - loss: 0.0072 - accuracy: 1.0000\n","Epoch 93/150\n","1/1 [==============================] - 0s 13ms/step - loss: 0.2235 - accuracy: 0.9167\n","Epoch 94/150\n","1/1 [==============================] - 0s 14ms/step - loss: 0.0067 - accuracy: 1.0000\n","Epoch 95/150\n","1/1 [==============================] - 0s 13ms/step - loss: 0.0024 - accuracy: 1.0000\n","Epoch 96/150\n","1/1 [==============================] - 0s 13ms/step - loss: 0.0093 - accuracy: 1.0000\n","Epoch 97/150\n","1/1 [==============================] - 0s 13ms/step - loss: 0.0032 - accuracy: 1.0000\n","Epoch 98/150\n","1/1 [==============================] - 0s 13ms/step - loss: 0.0278 - accuracy: 1.0000\n","Epoch 99/150\n","1/1 [==============================] - 0s 13ms/step - loss: 0.0187 - accuracy: 1.0000\n","Epoch 100/150\n","1/1 [==============================] - 0s 14ms/step - loss: 0.0100 - accuracy: 1.0000\n","Epoch 101/150\n","1/1 [==============================] - 0s 14ms/step - loss: 0.0255 - accuracy: 1.0000\n","Epoch 102/150\n","1/1 [==============================] - 0s 13ms/step - loss: 2.1954e-04 - accuracy: 1.0000\n","Epoch 103/150\n","1/1 [==============================] - 0s 22ms/step - loss: 0.0053 - accuracy: 1.0000\n","Epoch 104/150\n","1/1 [==============================] - 0s 19ms/step - loss: 0.0206 - accuracy: 1.0000\n","Epoch 105/150\n","1/1 [==============================] - 0s 19ms/step - loss: 0.0053 - accuracy: 1.0000\n","Epoch 106/150\n","1/1 [==============================] - 0s 13ms/step - loss: 0.0113 - accuracy: 1.0000\n","Epoch 107/150\n","1/1 [==============================] - 0s 13ms/step - loss: 0.0055 - accuracy: 1.0000\n","Epoch 108/150\n","1/1 [==============================] - 0s 13ms/step - loss: 0.0027 - accuracy: 1.0000\n","Epoch 109/150\n","1/1 [==============================] - 0s 13ms/step - loss: 0.0060 - accuracy: 1.0000\n","Epoch 110/150\n","1/1 [==============================] - 0s 13ms/step - loss: 0.0333 - accuracy: 1.0000\n","Epoch 111/150\n","1/1 [==============================] - 0s 15ms/step - loss: 0.0419 - accuracy: 1.0000\n","Epoch 112/150\n","1/1 [==============================] - 0s 13ms/step - loss: 0.0028 - accuracy: 1.0000\n","Epoch 113/150\n","1/1 [==============================] - 0s 13ms/step - loss: 0.0036 - accuracy: 1.0000\n","Epoch 114/150\n","1/1 [==============================] - 0s 14ms/step - loss: 0.0013 - accuracy: 1.0000\n","Epoch 115/150\n","1/1 [==============================] - 0s 14ms/step - loss: 0.0571 - accuracy: 0.9583\n","Epoch 116/150\n","1/1 [==============================] - 0s 14ms/step - loss: 0.0019 - accuracy: 1.0000\n","Epoch 117/150\n","1/1 [==============================] - 0s 13ms/step - loss: 0.0124 - accuracy: 1.0000\n","Epoch 118/150\n","1/1 [==============================] - 0s 13ms/step - loss: 0.0333 - accuracy: 1.0000\n","Epoch 119/150\n","1/1 [==============================] - 0s 14ms/step - loss: 0.0061 - accuracy: 1.0000\n","Epoch 120/150\n","1/1 [==============================] - 0s 13ms/step - loss: 0.0025 - accuracy: 1.0000\n","Epoch 121/150\n","1/1 [==============================] - 0s 17ms/step - loss: 0.0078 - accuracy: 1.0000\n","Epoch 122/150\n","1/1 [==============================] - 0s 17ms/step - loss: 0.0075 - accuracy: 1.0000\n","Epoch 123/150\n","1/1 [==============================] - 0s 14ms/step - loss: 0.0012 - accuracy: 1.0000\n","Epoch 124/150\n","1/1 [==============================] - 0s 13ms/step - loss: 0.1031 - accuracy: 0.9583\n","Epoch 125/150\n","1/1 [==============================] - 0s 13ms/step - loss: 0.0013 - accuracy: 1.0000\n","Epoch 126/150\n","1/1 [==============================] - 0s 13ms/step - loss: 0.0038 - accuracy: 1.0000\n","Epoch 127/150\n","1/1 [==============================] - 0s 12ms/step - loss: 0.0015 - accuracy: 1.0000\n","Epoch 128/150\n","1/1 [==============================] - 0s 14ms/step - loss: 0.0014 - accuracy: 1.0000\n","Epoch 129/150\n","1/1 [==============================] - 0s 13ms/step - loss: 0.0057 - accuracy: 1.0000\n","Epoch 130/150\n","1/1 [==============================] - 0s 15ms/step - loss: 0.0060 - accuracy: 1.0000\n","Epoch 131/150\n","1/1 [==============================] - 0s 14ms/step - loss: 0.0042 - accuracy: 1.0000\n","Epoch 132/150\n","1/1 [==============================] - 0s 14ms/step - loss: 0.0137 - accuracy: 1.0000\n","Epoch 133/150\n","1/1 [==============================] - 0s 16ms/step - loss: 0.0084 - accuracy: 1.0000\n","Epoch 134/150\n","1/1 [==============================] - 0s 13ms/step - loss: 0.0114 - accuracy: 1.0000\n","Epoch 135/150\n","1/1 [==============================] - 0s 13ms/step - loss: 0.0310 - accuracy: 1.0000\n","Epoch 136/150\n","1/1 [==============================] - 0s 13ms/step - loss: 0.0219 - accuracy: 1.0000\n","Epoch 137/150\n","1/1 [==============================] - 0s 15ms/step - loss: 0.0050 - accuracy: 1.0000\n","Epoch 138/150\n","1/1 [==============================] - 0s 14ms/step - loss: 7.2084e-04 - accuracy: 1.0000\n","Epoch 139/150\n","1/1 [==============================] - 0s 14ms/step - loss: 0.0079 - accuracy: 1.0000\n","Epoch 140/150\n","1/1 [==============================] - 0s 15ms/step - loss: 0.0496 - accuracy: 1.0000\n","Epoch 141/150\n","1/1 [==============================] - 0s 14ms/step - loss: 0.0011 - accuracy: 1.0000\n","Epoch 142/150\n","1/1 [==============================] - 0s 15ms/step - loss: 0.0139 - accuracy: 1.0000\n","Epoch 143/150\n","1/1 [==============================] - 0s 14ms/step - loss: 0.0012 - accuracy: 1.0000\n","Epoch 144/150\n","1/1 [==============================] - 0s 14ms/step - loss: 0.0059 - accuracy: 1.0000\n","Epoch 145/150\n","1/1 [==============================] - 0s 14ms/step - loss: 0.0602 - accuracy: 0.9583\n","Epoch 146/150\n","1/1 [==============================] - 0s 14ms/step - loss: 0.0026 - accuracy: 1.0000\n","Epoch 147/150\n","1/1 [==============================] - 0s 14ms/step - loss: 0.0119 - accuracy: 1.0000\n","Epoch 148/150\n","1/1 [==============================] - 0s 16ms/step - loss: 0.0018 - accuracy: 1.0000\n","Epoch 149/150\n","1/1 [==============================] - 0s 17ms/step - loss: 0.0064 - accuracy: 1.0000\n","Epoch 150/150\n","1/1 [==============================] - 0s 15ms/step - loss: 0.0082 - accuracy: 1.0000\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x7dcedfd95930>"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["#7 Preprocessing the Input\n","def clean_text(text):\n","  tokens = nltk.word_tokenize (text)\n","  tokens = [lemmatizer.lemmatize(word) for word in tokens]\n","  return tokens\n","\n","def bag_of_words (text, vocab):\n","  tokens = clean_text(text)\n","  bow = [0]*len(vocab)\n","  for w in tokens:\n","    for idx, word in enumerate(vocab):\n","      if word == w:\n","        bow[idx]=1\n","  return np.array (bow)\n","\n","def pred_class(text, vocab, labels):\n","  bow = bag_of_words(text, vocab)\n","  result = model.predict(np.array([bow]))[0] #Extracting probabilities\n","  thresh = 0.5\n","  y_pred = [[indx, res] for indx, res in enumerate(result) if res > thresh]\n","  y_pred.sort(key=lambda x: x[1], reverse=True) #Sorting by values of probability in decreasing order\n","  return_list = []\n","  for r in y_pred:\n","     return_list.append(labels[r[0]]) #Contains labels (tags) for highest probability\n","  return return_list\n","\n","def get_response(intents_list, intents_json):\n","  if len(intents_list) == 0:\n","    result = \"Sorry! I don't understand.\"\n","  else:\n","    tag = intents_list[0]\n","    list_of_intents = intents_json[\"intents\"]\n","    for i in list_of_intents:\n","      if i[\"tag\"] == tag:\n","        result = random.choice(i[\"responses\"])\n","        break\n","  return result"],"metadata":{"id":"LbfQrbncrgG3","executionInfo":{"status":"ok","timestamp":1712043846528,"user_tz":-330,"elapsed":438,"user":{"displayName":"Arun Kumar","userId":"06687701211405974628"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["#8 Interacting with the chatbot\n","print(\"Press Ø if you don't want to chat with our ChatBot.\")\n","while True:\n","  message = input(\"\")\n","  if message == \"0\":\n","    break\n","  intents=pred_class(message, words, classes)\n","  result = get_response (intents, data)\n","  print(result)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JE1SH5lHvWkb","executionInfo":{"status":"ok","timestamp":1712044100235,"user_tz":-330,"elapsed":250794,"user":{"displayName":"Arun Kumar","userId":"06687701211405974628"}},"outputId":"36b6086a-739a-4125-9143-beb2a66ba182"},"execution_count":22,"outputs":[{"name":"stdout","output_type":"stream","text":["Press Ø if you don't want to chat with our ChatBot.\n","hi\n","1/1 [==============================] - 0s 23ms/step\n","Hi there, how can I help?\n","how are you\n","1/1 [==============================] - 0s 22ms/step\n","Hi there, how can I help?\n","good morning\n","1/1 [==============================] - 0s 30ms/step\n","Good to see you again\n","how do you do\n","1/1 [==============================] - 0s 21ms/step\n","Hi there, how can I help?\n","hello\n","1/1 [==============================] - 0s 26ms/step\n","Hi there, how can I help?\n","what is you name\n","1/1 [==============================] - 0s 25ms/step\n","weather today : 30\n","what is alpha\n","1/1 [==============================] - 0s 22ms/step\n","weather today : 30\n","then\n","1/1 [==============================] - 0s 22ms/step\n","Hi there, how can I help?\n","i am goo\n","1/1 [==============================] - 0s 117ms/step\n","Hello, thanks for visiting\n","can i talk to you\n","1/1 [==============================] - 0s 23ms/step\n","My pleasure\n","my name is arun\n","1/1 [==============================] - 0s 22ms/step\n","Hi there, how can I help?\n","what is special today\n","1/1 [==============================] - 0s 21ms/step\n","weather today : 30\n","tomorrow \n","1/1 [==============================] - 0s 20ms/step\n","weather tomorrow : 40\n","ok bye\n","1/1 [==============================] - 0s 21ms/step\n","Have a nice day\n","what is python\n","1/1 [==============================] - 0s 39ms/step\n","weather today : 30\n","0\n"]}]}]}